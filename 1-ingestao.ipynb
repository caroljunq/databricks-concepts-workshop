{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cd46340-40e4-4c98-9d72-3163bfd26cae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Criando cat√°logo e schema"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "url = f\"https://raw.githubusercontent.com/caroljunq/databricks-concepts-workshop/main/data/\"\n",
    "\n",
    "catalog_name = f\"workshop_rails\"\n",
    "schema_name  = f\"rails\"\n",
    "create_catalog = f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\"\n",
    "spark.sql (create_catalog)\n",
    "\n",
    "\n",
    "create_schema = f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\"\n",
    "spark.sql (create_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2889a4e8-5644-4e94-8093-5a828703138c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Carga da tabela de frota de locomotivas"
    }
   },
   "outputs": [],
   "source": [
    "entity_name  = f\"frota_locomotivas\"\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6a957d7-d1be-41c8-822f-7459622772ed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Carga da tabela de geografia das linhas"
    }
   },
   "outputs": [],
   "source": [
    "entity_name  = f\"geografia_linha\"\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "648d804b-78bb-4d6b-9b12-dc3e996b0eaa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Carga da tabela de monitoramento dos trilhos"
    }
   },
   "outputs": [],
   "source": [
    "entity_name  = f\"monitoramento_trilhos\"\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38b6353b-883b-4d4c-ada9-6df63c347653",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Carga da tabela de paradas dsa locomotivas"
    }
   },
   "outputs": [],
   "source": [
    "entity_name  = f\"paradas\"\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77897b44-dc52-4835-852d-4a6622957b84",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Carga da tabela a ser usada no automl"
    }
   },
   "outputs": [],
   "source": [
    "entity_name  = f\"automl\" #Telemetria de consumo\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1-ingestao",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}